{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "m-QbZLFlyjCA",
        "cdzvZUWNzQAY",
        "_8vKbM9TzkCb",
        "9aOdldqfyoSt",
        "4rSZ0nNXXi1A",
        "0ty5QkTRkUW5",
        "6ElRLLrbv0op",
        "pKsq6UgsvrGu",
        "jQuP9L3Bxccy",
        "pJyew3dez2Wc",
        "_KprKABkwBxe",
        "2atmPsCD5ThV",
        "a4Ae9a4VE3O2",
        "mcIPdm2gkbP7",
        "X4eX_0UDwK0F",
        "Alvf6x5vwDkh",
        "VFsN4qoY1qFw",
        "B6yICeOH1qFz",
        "xHXKrn9M6L_s",
        "_i257mg66Lan",
        "JieVvX5XFKMT",
        "RZRZkudPkkDd",
        "lIwvJcJBwchg",
        "ZMJwIP8WwUjg",
        "o7FBIYbw4QVa",
        "BCsx6dqv4QVb",
        "PSXOlVSN4QVc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ドライブのマウント"
      ],
      "metadata": {
        "id": "m-QbZLFlyjCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9g8jY7G9ahIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d20f93-2d4a-443d-a172-2c6498edffa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Googleドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ライブラリ・モジュールのインポート"
      ],
      "metadata": {
        "id": "cdzvZUWNzQAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリの準備\n",
        "!pip install timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from timm.scheduler import CosineLRScheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import pickle"
      ],
      "metadata": {
        "id": "l8wfSjPuboGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d7f6a6-e007-4da6-bc7b-08bc1c533658"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### シード値の設定"
      ],
      "metadata": {
        "id": "_8vKbM9TzkCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# シード値を設定\n",
        "def fix_seed(seed=1234):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "fix_seed(seed=1234)"
      ],
      "metadata": {
        "id": "pGX4Zk1LbtPr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットの準備"
      ],
      "metadata": {
        "id": "9aOdldqfyoSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 平均値と標準偏差を計算するためのCIFAR10データセットの前処理を定義\n",
        "pre_transform_cifar10 = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 平均値と標準偏差を計算するためのCIFAR10データセットの読み込み\n",
        "pre_train_dataset_cifar10 = datasets.CIFAR10(root='/content/data/', download=True, transform=pre_transform_cifar10)\n",
        "\n",
        "# 平均値と標準偏差を計算するための変数を初期化\n",
        "pre_mean_cifar10 = 0.0\n",
        "pre_std_cifar10 = 0.0\n",
        "pre_total_samples_cifar10 = len(pre_train_dataset_cifar10)\n",
        "\n",
        "# データセットのすべてのデータポイントに対して平均値と標準偏差を計算\n",
        "for data in pre_train_dataset_cifar10:\n",
        "    pre_image, _ = data\n",
        "    pre_mean_cifar10 += pre_image.mean(dim=(1, 2))  # テンソルのチャンネルごとに平均を計算\n",
        "    pre_std_cifar10 += pre_image.std(dim=(1, 2))    # テンソルのチャンネルごとに標準偏差を計算\n",
        "\n",
        "# データセット全体の平均値と標準偏差を計算\n",
        "pre_mean_cifar10 /= pre_total_samples_cifar10\n",
        "pre_std_cifar10 /= pre_total_samples_cifar10\n",
        "\n",
        "print(\"データセット全体の平均値: \", pre_mean_cifar10)\n",
        "print(\"データセット全体の標準偏差: \", pre_std_cifar10)"
      ],
      "metadata": {
        "id": "RLSipTJ0bu1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b7ae30-747d-4da1-c972-ccaf35e12736"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9003779.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/cifar-10-python.tar.gz to /content/data/\n",
            "データセット全体の平均値:  tensor([0.4914, 0.4822, 0.4465])\n",
            "データセット全体の標準偏差:  tensor([0.2023, 0.1994, 0.2010])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用のCIFAR10データセットの前処理を定義\n",
        "train_transform_cifar10 = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=pre_mean_cifar10, std=pre_std_cifar10)\n",
        "    ])\n",
        "# テスト用のCIFAR10データセットの前処理を定義\n",
        "test_transform_cifar10 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=pre_mean_cifar10, std=pre_std_cifar10)\n",
        "    ])\n",
        "\n",
        "# 学習用のCIFAR10データセットの読み込み\n",
        "train_dataset_cifar10 = torchvision.datasets.CIFAR10(root='/content/data/', train=True, transform=train_transform_cifar10, download=True)\n",
        "# テスト用のCIFAR10データセットの読み込み\n",
        "test_dataset_cifar10 = torchvision.datasets.CIFAR10(root='/content/data/', train=False, transform=test_transform_cifar10, download=True)\n",
        "\n",
        "# 学習用のCIFAR10データローダーを作成\n",
        "train_loader_cifar10 = torch.utils.data.DataLoader(dataset=train_dataset_cifar10, batch_size=512, shuffle=True, num_workers=2)\n",
        "# テスト用のCIFAR10データローダーを作成\n",
        "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10, batch_size=512, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ah3PRB7vb1UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266b04a3-22dc-489d-a686-c31198176ac6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの実装"
      ],
      "metadata": {
        "id": "4rSZ0nNXXi1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1×1のサブネットワーク獲得用の畳み込みを定義\n",
        "def supermaskconv1x1(in_channels, out_channels, stride=1):\n",
        "    return SupermaskConv(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "# 3×3のサブネットワーク獲得用の畳み込みを定義\n",
        "def supermaskconv3x3(in_channels, out_channels, stride=1):\n",
        "    return SupermaskConv(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)"
      ],
      "metadata": {
        "id": "LGXnnKFiXoBI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サブネットワーク獲得用のバッチ正則化として、非アフィン正規化を使用する（学習可能なパラメータを使用しない）\n",
        "class NonAffineBatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, dim):\n",
        "        super(NonAffineBatchNorm, self).__init__(dim, affine=False)"
      ],
      "metadata": {
        "id": "lsTzgaTYXum7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 各重みにスコアを付与したスコアをソートしてtop k%を使用することでサブネットワークを獲得する\n",
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # スコアを複製する\n",
        "        out = scores.clone()\n",
        "        # スコアを昇順でソートする\n",
        "        _, idx = scores.flatten().sort()\n",
        "        # top k%以下のスコアの数\n",
        "        j = int((1 - k) * scores.numel())\n",
        "        # flat_outとoutは同じメモリを参照する（flat_outを変更するとoutにも影響する）\n",
        "        flat_out = out.flatten()\n",
        "        # top k%の要素を1にする\n",
        "        flat_out[idx[j:]] = 1\n",
        "        # top k%以外の要素を0にする\n",
        "        flat_out[idx[:j]] = 0\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        # 逆伝播時に勾配gをそのまま伝える\n",
        "        return g, None"
      ],
      "metadata": {
        "id": "MWW1Jx9JXzGI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サブネットワーク獲得用の畳み込みを定義\n",
        "class SupermaskConv(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # 重みと同じ形状のスコアを用意\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        # スコアを一様分布で初期化\n",
        "        nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "        # 重みの勾配を無効化する\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def _init_conv(self):\n",
        "        # 重みを一様分布で初期化\n",
        "        if self.init == 'kaiming_uniform':\n",
        "            nn.init.kaiming_uniform_(self.weight, mode='fan_out', nonlinearity='relu')\n",
        "        # 重みを正規分布で初期化\n",
        "        elif self.init == 'kaiming_normal':\n",
        "            nn.init.kaiming_normal_(self.weight, mode='fan_out', nonlinearity='relu')\n",
        "        # 重みを符号つき定数で初期化\n",
        "        elif self.init == 'signed_constant':\n",
        "            fan = nn.init._calculate_correct_fan(self.weight, mode='fan_out')\n",
        "            gain = nn.init.calculate_gain('relu')\n",
        "            std = gain / math.sqrt(fan)\n",
        "            self.weight.data = self.weight.data.sign() * std\n",
        "\n",
        "    def set_init(self, init):\n",
        "        # 初期化手法を設定\n",
        "        self.init = init\n",
        "\n",
        "    def set_prune_rate(self, prune_rate):\n",
        "        # 刈り込み率を設定\n",
        "        self.prune_rate = prune_rate\n",
        "\n",
        "    @property\n",
        "    def clamped_scores(self):\n",
        "        # スコアとして非負の値を返すようにする（重要度を表す）\n",
        "        return self.scores.abs()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # サブネットワークを獲得\n",
        "        subnet = GetSubnet.apply(self.clamped_scores, 1 - self.prune_rate)\n",
        "        # サブネットワークでマスク\n",
        "        w = self.weight * subnet\n",
        "        x = F.conv2d(x, w, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GMJZoKQHZQu2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サブネットワーク獲得用のResidual Blocksを定義\n",
        "class SupermaskBuildingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.bn1 = NonAffineBatchNorm(in_channels)\n",
        "        self.conv1 = supermaskconv3x3(in_channels, out_channels, stride)\n",
        "        self.bn2 = NonAffineBatchNorm(out_channels)\n",
        "        self.conv2 = supermaskconv3x3(out_channels, out_channels)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 入力と出力のチャンネル数が異なる場合（strideが1より大きい場合）、ダウンサンプリング\n",
        "        if in_channels != out_channels or stride > 1:\n",
        "            self.shortcut = supermaskconv1x1(in_channels, out_channels, stride)\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.conv2(out)\n",
        "        # 残差写像と恒等写像の要素毎の和を計算\n",
        "        out += self.shortcut(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ESo-AKn0HM3s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SupermaskWideResNet(nn.Module):\n",
        "    def __init__(self, block, depth, k, num_classes=10):\n",
        "        super().__init__()\n",
        "        assert (depth - 4) % 6 == 0, \"depth should be 6n + 4\"\n",
        "        n = (depth - 4) // 6\n",
        "        channels = [16, 16 * k, 32 * k, 64 * k]\n",
        "        self.conv1 = supermaskconv3x3(3, channels[0])\n",
        "        # Residual Blocks（1)\n",
        "        self.layer1 = self._make_layer(block, channels[0], channels[1], n)\n",
        "        # Residual Blocks（2）\n",
        "        self.layer2 = self._make_layer(block, channels[1], channels[2], n, stride=2)\n",
        "        # Residual Blocks（3）\n",
        "        self.layer3 = self._make_layer(block, channels[2], channels[3], n, stride=2)\n",
        "        self.bn = NonAffineBatchNorm(channels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(channels[3], num_classes)\n",
        "\n",
        "        # 重みの初期化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # 初期化手法を設定\n",
        "                m.set_init(init)\n",
        "                # 刈り込み率を設定\n",
        "                m.set_prune_rate(prune_rate)\n",
        "                # 重みを初期化\n",
        "                m._init_conv()\n",
        "\n",
        "    # Residual Blocksを作成する関数を定義\n",
        "    def _make_layer(self, block, in_channels, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        # 最初の Residual Block（stride=stride）\n",
        "        layers.append(block(in_channels, out_channels, stride))\n",
        "        # 残りの Residual Block（stride=1）\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "o4DEbfdQH0hs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習と評価（100 epochs, init=kaiming_uniform）"
      ],
      "metadata": {
        "id": "b5CnW4IW4iww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.999"
      ],
      "metadata": {
        "id": "XGLNB5K_Eb5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.999_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.999_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUdmMBeNCokH",
        "outputId": "3fbba7fa-2e6f-4ad3-8de0-e23b132e54a8"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 29.314 %, Loss: 1.9843\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 43.624 %, Loss: 1.7559\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 50.242 %, Loss: 1.4006\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 53.31 %, Loss: 1.3620\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 54.088 %, Loss: 1.1950\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 54.658 %, Loss: 1.1987\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 55.234 %, Loss: 1.2516\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 55.184 %, Loss: 1.2165\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 55.59 %, Loss: 1.1932\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 56.44 %, Loss: 1.2763\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 56.274 %, Loss: 1.2122\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 56.322 %, Loss: 1.2457\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 56.61 %, Loss: 1.2276\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 56.354 %, Loss: 1.2023\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 56.768 %, Loss: 1.2717\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 56.766 %, Loss: 1.2782\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 56.814 %, Loss: 1.2414\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 56.844 %, Loss: 1.2404\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 57.38 %, Loss: 1.1916\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 57.594 %, Loss: 1.1140\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 57.29 %, Loss: 1.1270\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 57.054 %, Loss: 1.2054\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 57.848 %, Loss: 1.1042\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 57.756 %, Loss: 1.2167\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 57.724 %, Loss: 1.2710\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 58.224 %, Loss: 1.1585\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 57.616 %, Loss: 1.2131\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 57.722 %, Loss: 1.2358\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 57.894 %, Loss: 1.0587\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 58.008 %, Loss: 1.1687\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 58.252 %, Loss: 1.2131\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 58.144 %, Loss: 1.1635\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 58.242 %, Loss: 1.2089\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 58.93 %, Loss: 1.1363\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 58.19 %, Loss: 1.2613\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 58.318 %, Loss: 1.1883\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 58.73 %, Loss: 1.2365\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 58.804 %, Loss: 1.1791\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 58.574 %, Loss: 1.1250\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 58.996 %, Loss: 1.2681\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 58.974 %, Loss: 1.1894\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 58.97 %, Loss: 1.1755\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 58.92 %, Loss: 1.0828\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 59.27 %, Loss: 1.0966\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 59.124 %, Loss: 1.1765\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 59.202 %, Loss: 1.1985\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 59.21 %, Loss: 1.0776\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 59.474 %, Loss: 1.0271\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 59.254 %, Loss: 1.0558\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 59.318 %, Loss: 1.0814\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etp2AT1Rbptm",
        "outputId": "814618c7-3e08-4bca-e22d-fda9d1d6c875"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.999です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a7OBC3PdrKz",
        "outputId": "3e703cd9-3e0f-4f0b-c9a8-d9514ef9a4c5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbnhyD8vDdWO",
        "outputId": "61f76038-d63b-4777-9916-25446c48ab3d"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f45751-8b4d-4ff9-cb7f-9a5db1bb7406",
        "id": "VPS2IC-WEb5R"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 56.34 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "NKfkZTN0Eb5R"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.995"
      ],
      "metadata": {
        "id": "NqbMSuRrpjNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.995_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.995_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891a6e0d-9c83-42e7-dcb1-8db87eca2e0b",
        "id": "MkGq7iD0pjN8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 36.31 %, Loss: 1.8502\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 55.81 %, Loss: 1.5779\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 63.962 %, Loss: 0.9960\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 67.868 %, Loss: 0.8490\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 69.516 %, Loss: 0.9035\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 69.942 %, Loss: 0.8858\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 70.214 %, Loss: 0.7664\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 70.734 %, Loss: 0.9149\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 70.656 %, Loss: 0.8689\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 70.92 %, Loss: 0.8139\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 71.288 %, Loss: 0.7198\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 72.13 %, Loss: 0.7449\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 72.026 %, Loss: 0.8427\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 72.056 %, Loss: 0.7549\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 71.96 %, Loss: 0.7454\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 72.318 %, Loss: 0.8547\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 72.518 %, Loss: 0.8014\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 72.716 %, Loss: 0.8011\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 72.734 %, Loss: 0.7888\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 72.608 %, Loss: 0.7071\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 72.894 %, Loss: 0.6347\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 72.47 %, Loss: 0.8490\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 73.094 %, Loss: 0.7180\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 72.872 %, Loss: 0.8391\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 73.398 %, Loss: 0.8196\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 73.238 %, Loss: 0.8081\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 73.472 %, Loss: 0.8026\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 73.514 %, Loss: 0.8949\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 73.342 %, Loss: 0.8989\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 73.452 %, Loss: 0.7257\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 73.212 %, Loss: 0.8023\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 73.84 %, Loss: 0.6506\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 73.83 %, Loss: 0.7941\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 73.734 %, Loss: 0.7324\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 73.918 %, Loss: 0.7221\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 73.736 %, Loss: 0.7679\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 73.784 %, Loss: 0.6832\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 73.852 %, Loss: 0.7928\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 74.092 %, Loss: 0.7311\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 74.008 %, Loss: 0.6675\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 74.298 %, Loss: 0.7639\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 74.254 %, Loss: 0.7711\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 74.27 %, Loss: 0.7707\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 74.348 %, Loss: 0.7546\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 74.298 %, Loss: 0.7281\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 74.37 %, Loss: 0.7009\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 74.518 %, Loss: 0.7431\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 74.458 %, Loss: 0.8019\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 74.59 %, Loss: 0.7181\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 74.518 %, Loss: 0.7723\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775f3abc-8d65-4386-bfc3-2bda104c222f",
        "id": "jg3iGXzRpjN9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.995です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37939702-6cd1-450c-8a78-290cb932fc6b",
        "id": "7M8dj_pcpjN9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a948aa-d52e-4378-d8b3-f2eacec53e39",
        "id": "brxdcBfIpjN9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5460a8-a63c-4c17-8e83-b4ce632fc09a",
        "id": "ZVfoVbqrpjN9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 75.97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GoQgBKvNpjN9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.99"
      ],
      "metadata": {
        "id": "lRIgIz-4pzit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.99_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.99_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bfdba6-34c8-44bf-9eab-45980f42e3ac",
        "id": "TU8wv-8hpzit"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 35.55 %, Loss: 1.7883\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 59.102 %, Loss: 1.4889\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 68.766 %, Loss: 0.8502\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 72.258 %, Loss: 0.7280\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 73.554 %, Loss: 0.6751\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 74.314 %, Loss: 0.7467\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 75.062 %, Loss: 0.7801\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 74.996 %, Loss: 0.6922\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 75.5 %, Loss: 0.6909\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 76.082 %, Loss: 0.5890\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 76.264 %, Loss: 0.7350\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 76.458 %, Loss: 0.6447\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 76.612 %, Loss: 0.6662\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 77.012 %, Loss: 0.6132\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 77.192 %, Loss: 0.7928\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 77.018 %, Loss: 0.6162\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 76.944 %, Loss: 0.6243\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 77.346 %, Loss: 0.7218\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 77.386 %, Loss: 0.6064\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 77.132 %, Loss: 0.7106\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 77.53 %, Loss: 0.5502\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 77.28 %, Loss: 0.6974\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 77.542 %, Loss: 0.6800\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 77.914 %, Loss: 0.5989\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 77.94 %, Loss: 0.5998\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 77.77 %, Loss: 0.6616\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 77.996 %, Loss: 0.6470\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 77.696 %, Loss: 0.6292\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 78.154 %, Loss: 0.5191\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 77.952 %, Loss: 0.6282\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 78.38 %, Loss: 0.6967\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 78.21 %, Loss: 0.5896\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 78.476 %, Loss: 0.6827\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 78.088 %, Loss: 0.7794\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 78.624 %, Loss: 0.5983\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 78.326 %, Loss: 0.6044\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 78.654 %, Loss: 0.5436\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 78.768 %, Loss: 0.5577\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 78.852 %, Loss: 0.6850\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 78.648 %, Loss: 0.5218\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 78.544 %, Loss: 0.5760\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 78.896 %, Loss: 0.6067\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 78.878 %, Loss: 0.5549\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 79.116 %, Loss: 0.5388\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 79.078 %, Loss: 0.4614\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 78.942 %, Loss: 0.5777\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 78.99 %, Loss: 0.5874\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 79.162 %, Loss: 0.5776\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 79.28 %, Loss: 0.6186\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 79.094 %, Loss: 0.5580\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ea5bda-4725-4c88-c7d2-06c558586f71",
        "id": "v-An9AWNpziu"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.990です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f7a685-2e8f-411b-b702-e8fe155a35f8",
        "id": "mHvzdVrrpziu"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9ae606-5e1f-4d4f-c469-3a943f4061f8",
        "id": "h6zL_iAfpziu"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1055c577-860a-4069-bc90-0aa071561b26",
        "id": "Gn0LIrVEpziu"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.38 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "pKv1NeZFpziu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.95"
      ],
      "metadata": {
        "id": "_6ADYB7Wp6FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.95_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.95_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xDoTvA6qB5k",
        "outputId": "54539e92-46c2-46ab-e8f9-8490e1f165b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 35.086 %, Loss: 1.8317\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 60.69 %, Loss: 1.5224\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 71.624 %, Loss: 0.6969\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.246 %, Loss: 0.7257\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 76.668 %, Loss: 0.6643\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.356 %, Loss: 0.5970\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 77.814 %, Loss: 0.6580\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.3 %, Loss: 0.5818\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 78.906 %, Loss: 0.5585\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 79.114 %, Loss: 0.5594\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 79.566 %, Loss: 0.5847\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 79.584 %, Loss: 0.5895\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.158 %, Loss: 0.5298\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.086 %, Loss: 0.5801\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 80.256 %, Loss: 0.5713\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.45 %, Loss: 0.4698\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 80.48 %, Loss: 0.5631\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 80.33 %, Loss: 0.5546\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 80.83 %, Loss: 0.5581\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 80.572 %, Loss: 0.6480\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 80.858 %, Loss: 0.5948\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 80.936 %, Loss: 0.5052\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 80.69 %, Loss: 0.5203\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.15 %, Loss: 0.4614\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.206 %, Loss: 0.5131\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.116 %, Loss: 0.5411\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.362 %, Loss: 0.5100\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 81.408 %, Loss: 0.5663\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 81.432 %, Loss: 0.5006\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 81.262 %, Loss: 0.4645\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 81.492 %, Loss: 0.5771\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 81.56 %, Loss: 0.5504\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 81.702 %, Loss: 0.5484\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 81.722 %, Loss: 0.5324\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 81.72 %, Loss: 0.4813\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 81.766 %, Loss: 0.4678\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 81.75 %, Loss: 0.5718\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 81.906 %, Loss: 0.5154\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 81.958 %, Loss: 0.5898\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 81.97 %, Loss: 0.5170\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.178 %, Loss: 0.3750\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.28 %, Loss: 0.5088\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 82.324 %, Loss: 0.6201\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.34 %, Loss: 0.5113\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.086 %, Loss: 0.4678\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 82.268 %, Loss: 0.4318\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 82.364 %, Loss: 0.5054\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 82.282 %, Loss: 0.4806\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 82.55 %, Loss: 0.5073\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 82.372 %, Loss: 0.5109\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5f47fb-be17-4320-cf56-5e34c7429174",
        "id": "n3NzFshJp6FR"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.950です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77ba016-6c33-4682-b705-b21f1ea55e43",
        "id": "CpNLpONSp6FS"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e547c0eb-fb0a-4dc2-8060-91a9f8b6adf1",
        "id": "ZzTrzJ3ip6FS"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5986ed8e-c055-4a0c-fc3d-4251cabf98bc",
        "id": "shsBdnlYp6FS"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.34 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "M5kErUQsp6FS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.9"
      ],
      "metadata": {
        "id": "JZemFpwOqHR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.9_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.9_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH0Apj5PqHR-",
        "outputId": "334ec068-ff4f-4166-c41d-19691fe27a2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 35.9 %, Loss: 1.8280\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 62.598 %, Loss: 1.5529\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.126 %, Loss: 0.7235\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.44 %, Loss: 0.6376\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.21 %, Loss: 0.6060\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.812 %, Loss: 0.6146\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.378 %, Loss: 0.6004\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.748 %, Loss: 0.6591\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.09 %, Loss: 0.6867\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 79.528 %, Loss: 0.5814\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 79.502 %, Loss: 0.5193\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.364 %, Loss: 0.4813\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.44 %, Loss: 0.5992\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.396 %, Loss: 0.5266\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 80.502 %, Loss: 0.5309\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.658 %, Loss: 0.5508\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.304 %, Loss: 0.5507\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.08 %, Loss: 0.5562\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 80.98 %, Loss: 0.4692\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.108 %, Loss: 0.4810\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 81.468 %, Loss: 0.4594\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.344 %, Loss: 0.5664\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.188 %, Loss: 0.5213\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.344 %, Loss: 0.5279\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.646 %, Loss: 0.5471\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.748 %, Loss: 0.5119\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.876 %, Loss: 0.5504\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 81.856 %, Loss: 0.5965\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 81.992 %, Loss: 0.6128\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 81.796 %, Loss: 0.5241\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 81.874 %, Loss: 0.5844\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.096 %, Loss: 0.4106\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.186 %, Loss: 0.5198\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.072 %, Loss: 0.4855\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.204 %, Loss: 0.5263\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.524 %, Loss: 0.5673\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.32 %, Loss: 0.4661\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.596 %, Loss: 0.5471\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 82.56 %, Loss: 0.5104\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.436 %, Loss: 0.3902\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.728 %, Loss: 0.4711\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.574 %, Loss: 0.4887\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 82.586 %, Loss: 0.5139\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.77 %, Loss: 0.4919\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.758 %, Loss: 0.4816\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 82.854 %, Loss: 0.4876\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 82.83 %, Loss: 0.4820\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 82.876 %, Loss: 0.5204\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 82.96 %, Loss: 0.5820\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.038 %, Loss: 0.5099\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbX-WoiHqHR_",
        "outputId": "092399b2-5adc-4f79-800c-fcd2b459e825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.900です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8h6ktHqHR_",
        "outputId": "65f3e470-4702-4e70-c543-2b615df2c033"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWqTGq1DqHR_",
        "outputId": "4e2da8aa-f561-47dc-9f63-b0c9b67bb687"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4BAg4wpqHSA",
        "outputId": "bafda7dd-2829-4a8a-ffd0-fece2e4e96fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.06 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Hb_KVRnsqHSA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.7"
      ],
      "metadata": {
        "id": "Y4UVvVqgqNiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.7_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.7_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxuTMT2UqNiH",
        "outputId": "78894813-d77b-4bbd-b432-c7cf8d7ebd57"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 35.514 %, Loss: 1.8450\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.856 %, Loss: 1.5200\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.602 %, Loss: 0.7691\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.804 %, Loss: 0.6770\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.502 %, Loss: 0.5752\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.156 %, Loss: 0.5942\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.724 %, Loss: 0.4905\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.468 %, Loss: 0.5878\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 80.122 %, Loss: 0.5754\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.162 %, Loss: 0.5711\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.818 %, Loss: 0.5329\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 81.076 %, Loss: 0.5590\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.896 %, Loss: 0.5083\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 81.204 %, Loss: 0.5362\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.258 %, Loss: 0.6110\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.372 %, Loss: 0.5284\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.318 %, Loss: 0.4794\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.668 %, Loss: 0.5551\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.862 %, Loss: 0.5069\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.714 %, Loss: 0.5082\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 82.082 %, Loss: 0.5652\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.874 %, Loss: 0.5515\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.762 %, Loss: 0.5048\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 82.278 %, Loss: 0.5060\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.184 %, Loss: 0.4672\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.232 %, Loss: 0.5289\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 82.384 %, Loss: 0.4728\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.46 %, Loss: 0.4966\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.59 %, Loss: 0.5114\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.564 %, Loss: 0.5629\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.854 %, Loss: 0.4655\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.64 %, Loss: 0.5134\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.932 %, Loss: 0.4785\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.886 %, Loss: 0.4816\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 83.066 %, Loss: 0.4669\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.968 %, Loss: 0.5390\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 83.024 %, Loss: 0.5181\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 83.082 %, Loss: 0.5885\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 83.102 %, Loss: 0.4317\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 83.024 %, Loss: 0.4678\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 83.176 %, Loss: 0.5190\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.378 %, Loss: 0.4769\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.404 %, Loss: 0.4358\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.498 %, Loss: 0.4500\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.504 %, Loss: 0.4717\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.596 %, Loss: 0.4460\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.704 %, Loss: 0.4206\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.36 %, Loss: 0.4994\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.576 %, Loss: 0.4345\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.658 %, Loss: 0.4573\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbNrQNCAqNiI",
        "outputId": "8907b1e9-f34c-4c82-f159-d023cf2a6b1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.700です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVWwwKmPqNiI",
        "outputId": "1398312c-b254-44fa-c69c-a14873ce466b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGwPZA1QqNiI",
        "outputId": "faab6a24-e413-47b2-8062-1806b2e485ee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fUK0AL7qNiI",
        "outputId": "096b4d0a-38ae-41ac-fd53-4b4451a79f20"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.62 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "P0yCgmcsqNiI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.5"
      ],
      "metadata": {
        "id": "BxdxiNhUqUtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.5_uniform_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.5_uniform_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5t5PfxlqUtn",
        "outputId": "c1bcc619-4708-4d01-bcba-8cdbbc818de7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 36.086 %, Loss: 1.8360\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.28 %, Loss: 1.4770\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.42 %, Loss: 0.7501\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 76.172 %, Loss: 0.7447\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.908 %, Loss: 0.6256\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.232 %, Loss: 0.7210\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.932 %, Loss: 0.6071\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.524 %, Loss: 0.5432\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 80.3 %, Loss: 0.6616\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.08 %, Loss: 0.5287\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.746 %, Loss: 0.5436\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.874 %, Loss: 0.5016\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 81.038 %, Loss: 0.4678\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 81.496 %, Loss: 0.6477\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.364 %, Loss: 0.4705\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.622 %, Loss: 0.5855\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.546 %, Loss: 0.4554\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.842 %, Loss: 0.5389\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.886 %, Loss: 0.4450\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.916 %, Loss: 0.5515\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 82.192 %, Loss: 0.5124\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 82.326 %, Loss: 0.5563\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 82.374 %, Loss: 0.6266\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 82.616 %, Loss: 0.6016\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.39 %, Loss: 0.4892\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.704 %, Loss: 0.5225\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 82.67 %, Loss: 0.4540\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.638 %, Loss: 0.4995\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 83.18 %, Loss: 0.4639\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.98 %, Loss: 0.5585\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.998 %, Loss: 0.5649\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 83.086 %, Loss: 0.5011\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.764 %, Loss: 0.5152\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.994 %, Loss: 0.4516\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 83.208 %, Loss: 0.4562\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 83.222 %, Loss: 0.4699\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 83.218 %, Loss: 0.5401\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 83.392 %, Loss: 0.5893\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 83.454 %, Loss: 0.4869\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 83.594 %, Loss: 0.5236\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 83.48 %, Loss: 0.4888\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.418 %, Loss: 0.4061\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.538 %, Loss: 0.5242\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.546 %, Loss: 0.5174\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.696 %, Loss: 0.4770\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.636 %, Loss: 0.4801\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.798 %, Loss: 0.3841\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.54 %, Loss: 0.4877\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.604 %, Loss: 0.5780\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.854 %, Loss: 0.4667\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W97JiUXFqUto",
        "outputId": "fad995e9-8557-4d3c-af54-61301981f540"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.500です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_igSGIU6qUto",
        "outputId": "bce9a544-31bd-4344-ae19-d0417b02e8bc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOIcNLDzqUto",
        "outputId": "d634802f-0aee-466f-d6d7-2168cc13b361"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiKw0GhHqUto",
        "outputId": "e7c8074f-ede2-4b2b-8cbb-d5bf89c2ca4d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.61 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ikDtoXLbqUto"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習と評価（100 epochs, init=kaiming_normal）"
      ],
      "metadata": {
        "id": "2atmPsCD5ThV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.999"
      ],
      "metadata": {
        "id": "XohYpLpwsKjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.999_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.999_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc23c0ab-36b2-4467-da98-892b8146d874",
        "id": "AmY2J5YpsKjm"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 30.01 %, Loss: 1.9564\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 43.122 %, Loss: 1.7583\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 49.56 %, Loss: 1.3881\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 52.748 %, Loss: 1.3419\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 53.85 %, Loss: 1.3152\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 54.28 %, Loss: 1.2419\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 53.814 %, Loss: 1.2585\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 55.402 %, Loss: 1.2870\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 55.302 %, Loss: 1.2216\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 55.494 %, Loss: 1.2213\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 55.738 %, Loss: 1.2015\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 55.768 %, Loss: 1.1838\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 56.114 %, Loss: 1.2558\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 55.848 %, Loss: 1.2882\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 56.422 %, Loss: 1.2205\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 56.258 %, Loss: 1.1764\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 56.342 %, Loss: 1.1013\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 56.888 %, Loss: 1.2370\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 56.818 %, Loss: 1.1358\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 57.14 %, Loss: 1.3232\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 57.278 %, Loss: 1.1098\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 57.212 %, Loss: 1.2333\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 57.366 %, Loss: 1.1647\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 57.322 %, Loss: 1.2733\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 57.326 %, Loss: 1.2065\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 57.422 %, Loss: 1.3077\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 57.49 %, Loss: 1.2238\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 57.14 %, Loss: 1.1653\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 57.686 %, Loss: 1.2406\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 57.96 %, Loss: 1.2030\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 57.724 %, Loss: 1.2271\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 58.056 %, Loss: 1.2276\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 57.84 %, Loss: 1.2277\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 57.754 %, Loss: 1.2279\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 58.166 %, Loss: 1.1753\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 57.796 %, Loss: 1.2252\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 58.404 %, Loss: 1.1509\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 58.168 %, Loss: 1.2292\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 58.298 %, Loss: 1.2200\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 58.258 %, Loss: 1.0780\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 58.402 %, Loss: 1.1747\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 58.62 %, Loss: 1.2483\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 59.002 %, Loss: 1.2774\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 58.53 %, Loss: 1.1318\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 58.796 %, Loss: 1.2367\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 58.752 %, Loss: 1.1205\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 58.866 %, Loss: 1.1958\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 58.646 %, Loss: 1.2098\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 58.954 %, Loss: 1.1137\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 59.082 %, Loss: 1.1338\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc36c5b-bd31-4e0d-83e2-50940cd6bce3",
        "id": "9BhXxkuFsKjn"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.999です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e0b496-ebef-40fb-b1d4-5c9d2611bb27",
        "id": "b2_21nPhsKjn"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f40a391-5436-4dc8-a3eb-6476e966d784",
        "id": "gdRkxqThsKjn"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5099999d-639e-42ed-e842-4ea1dae4b182",
        "id": "4uT1Zu5xsKjn"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 62.07 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-ufE10onsKjo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.995"
      ],
      "metadata": {
        "id": "ckkkthdAsKjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.995_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.995_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fd0eb6-b54d-4854-bc1b-8f7f85a0d552",
        "id": "Ys6GaW9nsKjo"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 31.52 %, Loss: 1.8704\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 53.426 %, Loss: 1.6376\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 61.724 %, Loss: 1.0420\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 65.504 %, Loss: 0.9052\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 66.596 %, Loss: 0.8980\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 67.026 %, Loss: 0.9455\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 67.554 %, Loss: 0.7949\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 68.074 %, Loss: 0.8696\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 68.066 %, Loss: 0.9774\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 68.848 %, Loss: 0.8855\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 69.014 %, Loss: 0.8401\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 69.2 %, Loss: 0.8170\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 69.678 %, Loss: 0.8325\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 68.76 %, Loss: 0.8435\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 69.788 %, Loss: 0.8740\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 69.716 %, Loss: 0.7967\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 69.53 %, Loss: 0.9017\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 69.808 %, Loss: 0.8231\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 70.034 %, Loss: 0.9067\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 70.084 %, Loss: 0.7974\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 70.06 %, Loss: 0.8525\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 70.166 %, Loss: 0.7892\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 70.1 %, Loss: 0.9336\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 70.658 %, Loss: 0.9096\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 70.354 %, Loss: 0.7320\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 70.584 %, Loss: 0.7882\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 70.52 %, Loss: 0.8176\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 70.888 %, Loss: 0.7774\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 70.5 %, Loss: 0.8213\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 70.736 %, Loss: 0.8508\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 70.896 %, Loss: 0.7930\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 71.116 %, Loss: 0.8980\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 71.172 %, Loss: 0.7194\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 70.778 %, Loss: 0.8079\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 71.366 %, Loss: 0.7431\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 70.95 %, Loss: 0.8070\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 71.342 %, Loss: 0.7980\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 71.502 %, Loss: 0.8282\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 71.182 %, Loss: 0.7203\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 71.504 %, Loss: 0.8145\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 71.49 %, Loss: 0.8052\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 71.612 %, Loss: 0.8044\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 71.818 %, Loss: 0.6971\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 71.922 %, Loss: 0.7829\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 71.7 %, Loss: 0.8164\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 71.71 %, Loss: 0.8184\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 71.62 %, Loss: 0.7593\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 71.842 %, Loss: 0.7987\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 71.976 %, Loss: 0.7559\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 72.112 %, Loss: 0.7480\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325a6eab-e5a5-4246-b1ec-564d554652d5",
        "id": "FKdXWvTGsKjo"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.995です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43bf53a-fe73-404f-d457-b98c86e83370",
        "id": "av4C_G4hsKjo"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05fa0c8-795b-47be-d218-a26208deff40",
        "id": "g-VKHtD_sKjo"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e6dcc5-ed27-4367-847a-f762c98c7572",
        "id": "ZCufdW6FsKjo"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.55 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Y9-eOxW1sKjp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.99"
      ],
      "metadata": {
        "id": "VkScBTgxsKjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.99_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.99_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7404b52d-9f7d-4c6d-ac4d-22478aaa114a",
        "id": "QiH_-IeRsKjp"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 31.77 %, Loss: 1.8234\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 56.63 %, Loss: 1.5326\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 67.76 %, Loss: 0.8462\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 71.356 %, Loss: 0.7369\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 73.226 %, Loss: 0.7606\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 73.682 %, Loss: 0.6693\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 74.226 %, Loss: 0.7858\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 74.81 %, Loss: 0.7551\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 75.13 %, Loss: 0.7659\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 75.418 %, Loss: 0.7335\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 75.852 %, Loss: 0.6316\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 75.688 %, Loss: 0.6054\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 75.992 %, Loss: 0.7129\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 75.936 %, Loss: 0.6888\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 75.978 %, Loss: 0.6752\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 76.396 %, Loss: 0.6300\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 76.362 %, Loss: 0.6664\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 76.122 %, Loss: 0.6016\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 76.936 %, Loss: 0.6204\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 76.86 %, Loss: 0.6050\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 76.666 %, Loss: 0.7271\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 77.17 %, Loss: 0.6534\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 77.024 %, Loss: 0.6358\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 76.874 %, Loss: 0.6203\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 77.008 %, Loss: 0.6695\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 77.308 %, Loss: 0.6856\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 77.104 %, Loss: 0.6571\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 77.43 %, Loss: 0.6422\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 77.396 %, Loss: 0.6758\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 77.798 %, Loss: 0.5933\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 77.57 %, Loss: 0.6118\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 77.492 %, Loss: 0.5363\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 77.688 %, Loss: 0.6928\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 77.83 %, Loss: 0.7506\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 78.016 %, Loss: 0.5483\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 77.784 %, Loss: 0.7405\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 78.082 %, Loss: 0.5659\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 78.078 %, Loss: 0.6917\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 78.048 %, Loss: 0.5966\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 78.146 %, Loss: 0.5765\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 78.44 %, Loss: 0.6653\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 78.258 %, Loss: 0.6350\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 78.754 %, Loss: 0.5736\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 78.37 %, Loss: 0.6312\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 78.496 %, Loss: 0.6150\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 78.522 %, Loss: 0.6711\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 78.626 %, Loss: 0.6345\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 78.524 %, Loss: 0.6595\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 78.502 %, Loss: 0.6553\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 78.404 %, Loss: 0.6329\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJfgbkhZsKjp",
        "outputId": "b0091701-5ffd-4e19-8275-bfa77e38d6aa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.990です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH5bKN32sKjp",
        "outputId": "44742bba-d677-4222-e9f2-f49824683a0e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTHezonHsKjp",
        "outputId": "5da62f24-1400-4100-befe-521fe6ff7ba9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zrYAw0HsKjp",
        "outputId": "73667802-255c-4d47-ca41-fc2249fe9949"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 79.24 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "lHw2fRutsKjq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.95"
      ],
      "metadata": {
        "id": "jol7GLjisKjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.95_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.95_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_B7bedqsKjq",
        "outputId": "06180a7c-788d-496a-90a1-944b4d5e859c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 38.012 %, Loss: 1.8183\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.604 %, Loss: 1.5160\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 71.734 %, Loss: 0.7719\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.432 %, Loss: 0.7367\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 76.662 %, Loss: 0.6276\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.438 %, Loss: 0.6622\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.078 %, Loss: 0.6308\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.246 %, Loss: 0.6515\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.228 %, Loss: 0.5579\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 79.034 %, Loss: 0.6360\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 79.43 %, Loss: 0.5638\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 79.902 %, Loss: 0.5446\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.04 %, Loss: 0.5308\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.032 %, Loss: 0.4963\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 79.78 %, Loss: 0.5327\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.296 %, Loss: 0.6249\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 80.262 %, Loss: 0.5458\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 80.678 %, Loss: 0.6163\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 80.646 %, Loss: 0.5905\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 80.79 %, Loss: 0.6121\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 80.944 %, Loss: 0.5640\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 80.806 %, Loss: 0.5640\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.032 %, Loss: 0.4732\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.288 %, Loss: 0.5381\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.56 %, Loss: 0.5502\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.204 %, Loss: 0.5116\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.458 %, Loss: 0.4900\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 81.656 %, Loss: 0.5669\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 81.614 %, Loss: 0.5509\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 81.468 %, Loss: 0.4770\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 81.564 %, Loss: 0.4809\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 81.71 %, Loss: 0.4945\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 81.586 %, Loss: 0.5232\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 81.732 %, Loss: 0.4689\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 81.868 %, Loss: 0.4967\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 81.588 %, Loss: 0.6208\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 81.994 %, Loss: 0.5628\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 81.848 %, Loss: 0.5361\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 81.846 %, Loss: 0.4498\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.176 %, Loss: 0.4618\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 81.986 %, Loss: 0.4866\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.29 %, Loss: 0.4697\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 82.08 %, Loss: 0.5401\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.328 %, Loss: 0.5232\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.544 %, Loss: 0.4305\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 82.2 %, Loss: 0.4940\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 82.458 %, Loss: 0.4849\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 82.524 %, Loss: 0.5127\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 82.532 %, Loss: 0.5288\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 82.502 %, Loss: 0.5959\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aZxqP9IsKjq",
        "outputId": "c5b6f3f1-69c1-41d4-c210-6ebaed3aea7e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.950です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFnYJCFQsKjq",
        "outputId": "93cb074c-cf19-4116-e21d-992bb394a988"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDeN9Kt9sKjq",
        "outputId": "54fdc1fc-1e12-4df2-b425-b96fba8b3537"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxfuSX3GsKjq",
        "outputId": "1be15f3f-df28-455d-85dc-d307253d145b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.68 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "nF-avApBsKjr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.9"
      ],
      "metadata": {
        "id": "Y1vtYNaysKjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.9_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.9_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3yxTJAisKjr",
        "outputId": "ffef6a90-a902-4284-a783-911277da596b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 34.484 %, Loss: 1.8429\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 60.924 %, Loss: 1.5423\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 71.644 %, Loss: 0.8207\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.164 %, Loss: 0.6483\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 76.66 %, Loss: 0.6767\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.288 %, Loss: 0.6264\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 77.98 %, Loss: 0.5983\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.648 %, Loss: 0.6811\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 78.806 %, Loss: 0.5824\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 79.188 %, Loss: 0.5539\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 79.598 %, Loss: 0.5227\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.022 %, Loss: 0.5224\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.25 %, Loss: 0.5735\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.244 %, Loss: 0.6226\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 80.35 %, Loss: 0.4970\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.144 %, Loss: 0.7086\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 80.682 %, Loss: 0.5355\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 80.38 %, Loss: 0.4964\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 80.938 %, Loss: 0.5078\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 80.92 %, Loss: 0.5179\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 80.99 %, Loss: 0.6869\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.014 %, Loss: 0.6438\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.104 %, Loss: 0.5728\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.006 %, Loss: 0.5271\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.302 %, Loss: 0.4821\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.134 %, Loss: 0.5594\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.672 %, Loss: 0.7040\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 81.76 %, Loss: 0.5208\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 81.562 %, Loss: 0.4400\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 81.668 %, Loss: 0.4849\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 81.546 %, Loss: 0.4823\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 81.848 %, Loss: 0.5082\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 81.986 %, Loss: 0.5305\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 81.668 %, Loss: 0.5356\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 81.8 %, Loss: 0.5436\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.028 %, Loss: 0.4446\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.06 %, Loss: 0.6230\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.184 %, Loss: 0.4860\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 82.034 %, Loss: 0.4022\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.132 %, Loss: 0.4658\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.256 %, Loss: 0.5452\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.39 %, Loss: 0.4487\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 82.284 %, Loss: 0.4977\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.452 %, Loss: 0.4505\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.67 %, Loss: 0.4659\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 82.442 %, Loss: 0.4856\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 82.666 %, Loss: 0.4563\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 82.666 %, Loss: 0.4893\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 82.664 %, Loss: 0.5176\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 82.704 %, Loss: 0.4728\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCUErTQzsKjr",
        "outputId": "af6aa71d-463b-4ed9-ee97-9d40c58086d5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.900です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktJdEMAnsKjr",
        "outputId": "97de4582-4ff8-4090-d67d-964dd2d3058b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAm-mNessKjr",
        "outputId": "e3cdd33e-d146-48c5-c45d-a16e56fa3979"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ23nJSnsKjr",
        "outputId": "b61f4d02-b7ae-48f6-eb7d-d213f721d2fc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RZman30_sKjr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.7"
      ],
      "metadata": {
        "id": "wkPFUm8TsKjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.7_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.7_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-oqnFvsKjs",
        "outputId": "de5eda3e-7965-4c1a-bacc-fb3bc0393a16"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 34.6 %, Loss: 1.8014\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 60.886 %, Loss: 1.5370\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 71.846 %, Loss: 0.8007\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.354 %, Loss: 0.6962\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 76.978 %, Loss: 0.6141\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.506 %, Loss: 0.6228\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.168 %, Loss: 0.6234\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.732 %, Loss: 0.5561\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.214 %, Loss: 0.4794\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.006 %, Loss: 0.6302\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.216 %, Loss: 0.5208\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.318 %, Loss: 0.6177\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.456 %, Loss: 0.4905\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.564 %, Loss: 0.5711\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 80.68 %, Loss: 0.4758\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.666 %, Loss: 0.4958\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.368 %, Loss: 0.4840\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.15 %, Loss: 0.4993\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.572 %, Loss: 0.4738\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.324 %, Loss: 0.5227\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 81.36 %, Loss: 0.4935\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.4 %, Loss: 0.5356\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.634 %, Loss: 0.6072\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.542 %, Loss: 0.5244\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.812 %, Loss: 0.5195\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.926 %, Loss: 0.4789\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.818 %, Loss: 0.4951\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.166 %, Loss: 0.4799\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.244 %, Loss: 0.5599\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.242 %, Loss: 0.4700\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.218 %, Loss: 0.5006\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.314 %, Loss: 0.4792\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.424 %, Loss: 0.5259\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.274 %, Loss: 0.5335\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.47 %, Loss: 0.4626\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.54 %, Loss: 0.4737\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.424 %, Loss: 0.4525\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.696 %, Loss: 0.3662\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 82.812 %, Loss: 0.4578\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.894 %, Loss: 0.5523\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.562 %, Loss: 0.5120\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.926 %, Loss: 0.4904\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.082 %, Loss: 0.4265\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.9 %, Loss: 0.4917\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.95 %, Loss: 0.5040\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.05 %, Loss: 0.5603\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.08 %, Loss: 0.4480\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.126 %, Loss: 0.4270\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.104 %, Loss: 0.4446\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.186 %, Loss: 0.4884\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdIU4ohVsKjs",
        "outputId": "d29eb938-ab43-453a-b76c-9c4114f48005"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.700です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J_I6epfsKjs",
        "outputId": "a74b007e-a89c-4944-f891-ebac7273d00f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CKWYgN3sKjs",
        "outputId": "dcdb5c79-4b94-46ef-e75c-a6b2479f026f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ba207QsKjs",
        "outputId": "612a65ba-ad76-47ec-91c0-07abac4e3142"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.79 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xcVxnxg6sKjs"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.5"
      ],
      "metadata": {
        "id": "8W8kzd_SsKjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.5_normal_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.5_normal_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Resn6m1tsKjs",
        "outputId": "f10abd75-e5a8-4f73-abe6-d9f1ad0d9e49"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 36.25 %, Loss: 1.8549\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.88 %, Loss: 1.5166\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.696 %, Loss: 0.7224\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 76.044 %, Loss: 0.7009\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.692 %, Loss: 0.5624\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.316 %, Loss: 0.6667\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.812 %, Loss: 0.6082\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.4 %, Loss: 0.6347\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.764 %, Loss: 0.6184\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.182 %, Loss: 0.5062\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.518 %, Loss: 0.5349\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.614 %, Loss: 0.4626\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 81.036 %, Loss: 0.4976\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 81.214 %, Loss: 0.4873\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.064 %, Loss: 0.4859\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.274 %, Loss: 0.6163\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.308 %, Loss: 0.5501\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.77 %, Loss: 0.5083\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.526 %, Loss: 0.5245\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.71 %, Loss: 0.5507\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 81.986 %, Loss: 0.5565\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.946 %, Loss: 0.4730\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 82.188 %, Loss: 0.5198\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 82.0 %, Loss: 0.4207\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.12 %, Loss: 0.5054\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.156 %, Loss: 0.5347\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 82.08 %, Loss: 0.4990\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.162 %, Loss: 0.5741\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.586 %, Loss: 0.5048\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.616 %, Loss: 0.5103\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.65 %, Loss: 0.4452\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.612 %, Loss: 0.4580\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.79 %, Loss: 0.4927\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 83.016 %, Loss: 0.5060\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.772 %, Loss: 0.4736\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 83.172 %, Loss: 0.5175\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.798 %, Loss: 0.5122\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.976 %, Loss: 0.5460\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 83.126 %, Loss: 0.4812\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 83.012 %, Loss: 0.4783\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 83.264 %, Loss: 0.4230\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.4 %, Loss: 0.5302\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.206 %, Loss: 0.4239\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.328 %, Loss: 0.4487\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.604 %, Loss: 0.4895\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.446 %, Loss: 0.4557\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.344 %, Loss: 0.4957\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.626 %, Loss: 0.4733\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.568 %, Loss: 0.4908\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.696 %, Loss: 0.4691\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_x414z_sKjt",
        "outputId": "94723b06-5b46-4e02-cb99-725f6fb99dd8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.500です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXcOmaxJsKjt",
        "outputId": "0c7bfd6a-5574-43be-fafa-bb02a7de3661"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-9nEL2msKjt",
        "outputId": "61f948af-98ad-4f82-84f6-d4988c153489"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRLJ9NWVsKjt",
        "outputId": "b9429fc3-e12a-4131-fde9-30871ab88eae"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.64 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KhAW-8QqsKjt"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習と評価（100 epochs, init=signed_constant）"
      ],
      "metadata": {
        "id": "_i257mg66Lan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.999"
      ],
      "metadata": {
        "id": "Htel3svDs206"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.999_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.999_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b97c77-17c7-488c-8c9c-0d79fb583a9e",
        "id": "Tn-SMFp7s21G"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 28.234 %, Loss: 1.9513\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 46.34 %, Loss: 1.7991\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 54.576 %, Loss: 1.2176\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 57.722 %, Loss: 1.1337\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 58.552 %, Loss: 1.2002\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 58.746 %, Loss: 1.3233\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 59.632 %, Loss: 1.2679\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 59.588 %, Loss: 1.2879\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 60.274 %, Loss: 1.2073\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 60.292 %, Loss: 1.0883\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 60.716 %, Loss: 1.1665\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 60.618 %, Loss: 1.2280\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 61.256 %, Loss: 1.0953\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 60.83 %, Loss: 0.9958\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 61.294 %, Loss: 1.0876\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 61.518 %, Loss: 1.0718\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 61.48 %, Loss: 1.0899\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 61.782 %, Loss: 1.0404\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 61.842 %, Loss: 1.1351\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 61.812 %, Loss: 1.0762\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 62.136 %, Loss: 0.9594\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 62.094 %, Loss: 1.1620\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 62.17 %, Loss: 0.9420\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 61.962 %, Loss: 1.1000\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 62.3 %, Loss: 1.0162\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 62.158 %, Loss: 1.0338\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 62.588 %, Loss: 1.0578\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 62.474 %, Loss: 1.0210\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 62.522 %, Loss: 1.0941\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 62.7 %, Loss: 1.0059\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 63.018 %, Loss: 0.9937\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 63.084 %, Loss: 1.1042\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 62.948 %, Loss: 1.0706\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 63.024 %, Loss: 0.9254\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 63.256 %, Loss: 1.1299\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 63.03 %, Loss: 1.0266\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 63.184 %, Loss: 1.0792\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 63.43 %, Loss: 1.1232\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 63.24 %, Loss: 0.9597\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 63.154 %, Loss: 1.1638\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 63.742 %, Loss: 1.0961\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 63.674 %, Loss: 0.9252\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 63.668 %, Loss: 1.0295\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 63.742 %, Loss: 1.0109\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 63.92 %, Loss: 0.9509\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 63.666 %, Loss: 1.0624\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 63.77 %, Loss: 1.0224\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 63.976 %, Loss: 1.0182\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 63.716 %, Loss: 1.0367\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 64.016 %, Loss: 0.9551\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332cedf5-cbe4-4a9b-bfe3-9c0beb7bee81",
        "id": "UNPEeFvms21G"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.999です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60695c7e-7b4d-45f9-a938-9051b468e0a0",
        "id": "4Hw5ym78s21G"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352d83a8-82e0-4e0b-9215-738383aad446",
        "id": "Yc0q_v-as21H"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c467e32e-43cd-43d6-b565-f5eeeed5e201",
        "id": "wTIz7vT0s21H"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 65.93 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "adYD1gbrs21H"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.995"
      ],
      "metadata": {
        "id": "kAI328b9s21H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.995_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.995_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865585ef-2f38-4211-ca10-068cc7db72b8",
        "id": "0qd4qkxos21H"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 37.44 %, Loss: 1.8142\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 57.374 %, Loss: 1.4794\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 67.936 %, Loss: 0.8461\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 71.438 %, Loss: 0.7455\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 72.826 %, Loss: 0.8326\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 73.252 %, Loss: 0.8641\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 73.964 %, Loss: 0.7294\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 74.248 %, Loss: 0.7211\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 75.042 %, Loss: 0.6141\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 75.146 %, Loss: 0.7362\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 74.814 %, Loss: 0.7179\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 75.866 %, Loss: 0.7014\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 75.804 %, Loss: 0.7334\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 76.206 %, Loss: 0.6169\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 76.008 %, Loss: 0.5891\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 76.078 %, Loss: 0.6519\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 76.34 %, Loss: 0.6811\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 76.244 %, Loss: 0.6900\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 76.258 %, Loss: 0.7648\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 76.544 %, Loss: 0.7286\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 76.772 %, Loss: 0.8191\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 76.65 %, Loss: 0.6720\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 76.56 %, Loss: 0.6444\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 76.628 %, Loss: 0.6649\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 76.666 %, Loss: 0.7197\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 77.076 %, Loss: 0.6946\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 76.984 %, Loss: 0.6188\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 76.598 %, Loss: 0.6203\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 76.98 %, Loss: 0.6476\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 77.032 %, Loss: 0.7028\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 77.202 %, Loss: 0.7243\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 77.262 %, Loss: 0.6857\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 77.212 %, Loss: 0.6794\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 77.676 %, Loss: 0.5924\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 77.342 %, Loss: 0.7165\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 77.532 %, Loss: 0.6635\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 77.786 %, Loss: 0.5771\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 77.86 %, Loss: 0.6377\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 77.842 %, Loss: 0.7366\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 77.928 %, Loss: 0.6232\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 77.938 %, Loss: 0.5711\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 77.936 %, Loss: 0.6631\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 78.012 %, Loss: 0.5535\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 77.986 %, Loss: 0.6620\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 78.176 %, Loss: 0.5894\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 78.38 %, Loss: 0.6074\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 78.208 %, Loss: 0.6418\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 78.17 %, Loss: 0.7007\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 78.386 %, Loss: 0.5760\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 78.236 %, Loss: 0.5678\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db8ab66-72e3-4377-98a1-a7285af0f68b",
        "id": "r-HW5IK_s21H"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.995です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc631862-2ff6-4250-eb83-0593c9d17871",
        "id": "1LJb0Krws21H"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d10daa-d5e6-4309-a810-ba27751c465d",
        "id": "0qCmgtNHs21I"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9c0949-e602-478e-88eb-d9173ceb79b4",
        "id": "Lfmi-sz_s21I"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 79.59 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8HWIItpbs21I"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.99"
      ],
      "metadata": {
        "id": "N6XhVlw1s21I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.99_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.99_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498bebbc-57eb-421f-e60e-4be45d4e37a2",
        "id": "DbZHlg62s21I"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 34.216 %, Loss: 1.8214\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 58.824 %, Loss: 1.4932\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 70.648 %, Loss: 0.7553\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 74.33 %, Loss: 0.7007\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 75.824 %, Loss: 0.6486\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 76.27 %, Loss: 0.7064\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 76.826 %, Loss: 0.5850\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 77.302 %, Loss: 0.7058\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 77.858 %, Loss: 0.5806\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 78.102 %, Loss: 0.6876\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 78.446 %, Loss: 0.6065\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 78.324 %, Loss: 0.6831\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 78.596 %, Loss: 0.6546\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 78.728 %, Loss: 0.6319\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 78.918 %, Loss: 0.5358\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 78.852 %, Loss: 0.5369\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 79.086 %, Loss: 0.5205\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 79.26 %, Loss: 0.4970\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 78.99 %, Loss: 0.5863\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 78.94 %, Loss: 0.5693\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 79.3 %, Loss: 0.5577\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 79.572 %, Loss: 0.5900\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 79.592 %, Loss: 0.6164\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 79.97 %, Loss: 0.5811\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 80.086 %, Loss: 0.6193\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 79.932 %, Loss: 0.5680\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 79.896 %, Loss: 0.6376\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 80.102 %, Loss: 0.5431\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 80.278 %, Loss: 0.5337\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 80.124 %, Loss: 0.4837\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 80.584 %, Loss: 0.4730\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 80.1 %, Loss: 0.5507\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 80.344 %, Loss: 0.5192\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 80.344 %, Loss: 0.5523\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 80.364 %, Loss: 0.5682\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 80.462 %, Loss: 0.5580\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 80.486 %, Loss: 0.6350\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 80.65 %, Loss: 0.5278\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 80.724 %, Loss: 0.6016\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 80.84 %, Loss: 0.4655\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 80.85 %, Loss: 0.5059\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 80.654 %, Loss: 0.5955\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 80.71 %, Loss: 0.5234\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 80.906 %, Loss: 0.5988\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 81.03 %, Loss: 0.5113\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 80.938 %, Loss: 0.5843\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 81.07 %, Loss: 0.6114\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 81.07 %, Loss: 0.6110\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 81.22 %, Loss: 0.5590\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 81.188 %, Loss: 0.5691\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS1L0HJms21I",
        "outputId": "f1b04e71-a35a-46b2-90fe-f31980bc6854"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.990です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bliiLq6fs21J",
        "outputId": "a384126b-d0db-40d5-efbc-fafdc1ba833f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjjVdDxus21J",
        "outputId": "b449d65f-278d-44f7-a7f7-f351b6bffe17"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfBGy-xJs21J",
        "outputId": "ac38af97-b6d7-4177-dcfd-3dd315e93299"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 81.68 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "zO_k4GEqs21J"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.95"
      ],
      "metadata": {
        "id": "TJ7H2XHys21J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.95_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.95_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErQjafPns21J",
        "outputId": "9ea4fde4-3c13-444f-85fa-d63723ebe5f8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 34.73 %, Loss: 1.8311\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.886 %, Loss: 1.5059\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.21 %, Loss: 0.7394\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.734 %, Loss: 0.6446\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.02 %, Loss: 0.6888\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 77.922 %, Loss: 0.5995\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.486 %, Loss: 0.5539\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 78.748 %, Loss: 0.6760\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 78.916 %, Loss: 0.6588\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 79.722 %, Loss: 0.6034\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.21 %, Loss: 0.4943\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.092 %, Loss: 0.5968\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.264 %, Loss: 0.5693\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.524 %, Loss: 0.5682\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 80.554 %, Loss: 0.6226\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 80.786 %, Loss: 0.5176\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 80.65 %, Loss: 0.5380\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 80.962 %, Loss: 0.5924\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.018 %, Loss: 0.5167\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.02 %, Loss: 0.6238\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 81.242 %, Loss: 0.5361\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.096 %, Loss: 0.5182\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.276 %, Loss: 0.5095\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.316 %, Loss: 0.4585\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 81.212 %, Loss: 0.4831\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 81.558 %, Loss: 0.5483\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.524 %, Loss: 0.5878\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 81.33 %, Loss: 0.5369\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 81.622 %, Loss: 0.5591\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 81.956 %, Loss: 0.4981\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.064 %, Loss: 0.6103\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 81.978 %, Loss: 0.5568\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 81.992 %, Loss: 0.5174\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.116 %, Loss: 0.5356\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.19 %, Loss: 0.5103\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.048 %, Loss: 0.4012\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.258 %, Loss: 0.5190\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.212 %, Loss: 0.4320\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 82.388 %, Loss: 0.6463\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.462 %, Loss: 0.4800\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.194 %, Loss: 0.4373\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 82.592 %, Loss: 0.5546\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 82.568 %, Loss: 0.5311\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 82.546 %, Loss: 0.5229\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 82.608 %, Loss: 0.5535\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 82.634 %, Loss: 0.5643\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 82.644 %, Loss: 0.5615\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 82.724 %, Loss: 0.5182\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 82.76 %, Loss: 0.5257\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 82.81 %, Loss: 0.5292\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWR3MV5Us21J",
        "outputId": "15210aa2-a887-404a-f0cd-926de1f69e22"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.950です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DQxTiBGs21J",
        "outputId": "498e11f1-c558-42fb-8805-d6bdf4a7ac86"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzrsH2Dis21J",
        "outputId": "6c191b60-cd39-49ee-d6ca-90ae1cba5aac"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UoT7wX3s21K",
        "outputId": "c0f57cd6-5570-4a14-e215-f2bbd5c5a33d"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.54 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "9FtgtCFks21K"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.9"
      ],
      "metadata": {
        "id": "WUxMDoMfs21K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.9_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.9_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkANN8ohs21K",
        "outputId": "4bdcf45b-486f-4dc2-9ccb-0bb6055659fa"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 39.168 %, Loss: 1.8117\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.486 %, Loss: 1.4974\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 71.97 %, Loss: 0.8497\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 75.754 %, Loss: 0.5894\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.47 %, Loss: 0.6699\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.212 %, Loss: 0.5757\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.438 %, Loss: 0.5512\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.722 %, Loss: 0.6374\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.496 %, Loss: 0.6841\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.04 %, Loss: 0.5546\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 79.742 %, Loss: 0.5788\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.314 %, Loss: 0.5564\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.728 %, Loss: 0.4959\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 80.988 %, Loss: 0.5282\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.046 %, Loss: 0.6017\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.228 %, Loss: 0.5628\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.164 %, Loss: 0.5422\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.224 %, Loss: 0.5416\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.378 %, Loss: 0.5778\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.36 %, Loss: 0.3860\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 81.54 %, Loss: 0.4185\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 81.502 %, Loss: 0.5293\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 81.914 %, Loss: 0.4346\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.618 %, Loss: 0.5602\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.072 %, Loss: 0.5049\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.044 %, Loss: 0.3945\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 81.734 %, Loss: 0.5099\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.13 %, Loss: 0.4725\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.148 %, Loss: 0.5640\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.458 %, Loss: 0.4916\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.258 %, Loss: 0.4209\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.484 %, Loss: 0.4981\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.264 %, Loss: 0.5409\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.614 %, Loss: 0.4382\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.434 %, Loss: 0.4847\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.538 %, Loss: 0.5142\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 82.756 %, Loss: 0.5053\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 82.898 %, Loss: 0.5627\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 82.852 %, Loss: 0.5458\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 82.898 %, Loss: 0.5080\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 82.842 %, Loss: 0.4460\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.038 %, Loss: 0.5487\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.05 %, Loss: 0.4639\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.054 %, Loss: 0.5265\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.052 %, Loss: 0.4552\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.134 %, Loss: 0.5018\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.238 %, Loss: 0.4061\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.174 %, Loss: 0.5236\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.296 %, Loss: 0.4198\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.138 %, Loss: 0.4698\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWABLj1ds21K",
        "outputId": "2d293c95-50d4-49da-c0e1-b8cec2164bf1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.900です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc9CZSNAs21K",
        "outputId": "5b9e203b-4489-42d6-a037-36ad9d0c859a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsr5A2-6s21K",
        "outputId": "c4ce3067-d694-4e60-d7d0-c97bd506f3dc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iYQQFccs21K",
        "outputId": "e17a5fd9-8dc8-4e22-cf25-a8451047e4ef"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.18 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "VCZYzfPis21K"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.7"
      ],
      "metadata": {
        "id": "Cco3ZO64s21K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.7_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.7_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6iOOZK2s21L",
        "outputId": "da7c34d8-2e4f-4fae-837a-98aaeff26e51"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 34.808 %, Loss: 1.8381\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 63.188 %, Loss: 1.4911\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.692 %, Loss: 0.7605\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 76.382 %, Loss: 0.7291\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.706 %, Loss: 0.5324\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.65 %, Loss: 0.6275\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 79.058 %, Loss: 0.6477\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.678 %, Loss: 0.5719\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 80.176 %, Loss: 0.6087\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.064 %, Loss: 0.7597\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.538 %, Loss: 0.5274\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 80.86 %, Loss: 0.5378\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 81.092 %, Loss: 0.5332\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 81.31 %, Loss: 0.5576\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.384 %, Loss: 0.4591\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.514 %, Loss: 0.6075\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.88 %, Loss: 0.5350\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.674 %, Loss: 0.6095\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.878 %, Loss: 0.4471\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.756 %, Loss: 0.5246\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 82.044 %, Loss: 0.5223\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 82.086 %, Loss: 0.6193\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 82.098 %, Loss: 0.4137\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 82.248 %, Loss: 0.5136\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.18 %, Loss: 0.5062\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.296 %, Loss: 0.5250\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 82.588 %, Loss: 0.4745\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.652 %, Loss: 0.5267\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.402 %, Loss: 0.5508\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.682 %, Loss: 0.5113\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.498 %, Loss: 0.5927\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.854 %, Loss: 0.5348\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 83.07 %, Loss: 0.5049\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 82.95 %, Loss: 0.4717\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.896 %, Loss: 0.5180\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 83.194 %, Loss: 0.5077\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 83.196 %, Loss: 0.5458\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 83.144 %, Loss: 0.4827\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 83.256 %, Loss: 0.5223\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 83.194 %, Loss: 0.4869\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 83.262 %, Loss: 0.4429\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.2 %, Loss: 0.5076\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.382 %, Loss: 0.4868\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.504 %, Loss: 0.4920\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.348 %, Loss: 0.5088\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.554 %, Loss: 0.5061\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.784 %, Loss: 0.5183\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.606 %, Loss: 0.4390\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.474 %, Loss: 0.4312\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.684 %, Loss: 0.4805\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhsabi6fs21L",
        "outputId": "49bd62b2-45b2-4216-b568-4fc9b7140fe8"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.700です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNxpALBcs21L",
        "outputId": "155e1143-b279-4258-d6d8-f045951075e6"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOxbB0UZs21L",
        "outputId": "93c04d87-3264-42f6-bcec-e7f008e0d6d0"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFVsb7ZOs21L",
        "outputId": "b355d5a8-e2d7-4ec0-91c0-63b72bff2808"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.99 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "OLnXW3Pjs21L"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prune_rate=0.5"
      ],
      "metadata": {
        "id": "NOHLe2YEs21L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスを設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# モデルを定義\n",
        "model = torch.load('/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR100_100epochs_pr0.5_constant_CLRS_restest.pth')\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# 最終層以外のパラメータの勾配計算を停止\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 最終層のパラメータのみを学習するように設定\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "# モデルをデバイスに転送\n",
        "model = model.to(device)\n",
        "# 変更後のモデルの重みを保存\n",
        "model_init = copy.deepcopy(model)\n",
        "\n",
        "# 学習率を設定\n",
        "learning_rate = 0.01\n",
        "# 全体のepoch数を設定\n",
        "num_epochs = 50\n",
        "# warm-upするepoch数を設定\n",
        "warmup_epochs = 5\n",
        "\n",
        "# 損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザーを設定\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "# スケジューラーを設定\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, lr_min=1e-4, warmup_t=warmup_epochs, warmup_lr_init=1e-4, warmup_prefix=True)\n",
        "\n",
        "# モデルの学習\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_cifar10):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # 全データ数\n",
        "        total += labels.size(0)\n",
        "        # 正解数\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度を計算\n",
        "    train_acc = 100 * correct / total\n",
        "    # 正解率精度と損失を確認\n",
        "    print(\"Epoch [{}/{}], Train Accuracy: {} %, Loss: {:.4f}\".format(epoch+1, num_epochs, 100 * correct / total, loss.item()))\n",
        "    # 1エポック終了後にスケジューラーを更新\n",
        "    scheduler.step(epoch)\n",
        "    # 学習率の確認\n",
        "    print(\"Epoch [{}/{}], Learning Rate: {}\".format(epoch+1, num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "\n",
        "# モデルを保存\n",
        "torch.save(model, '/content/drive/MyDrive/SupermaskWideResNet28_10_CIFAR10_from_CIFAR100_100epochs_pr0.5_constant_50epochs_lr0.01_CLRS_restest.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702jIUxAs21L",
        "outputId": "ca2e7f40-5cab-467c-c529-5f3731631019"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Accuracy: 36.238 %, Loss: 1.8601\n",
            "Epoch [1/50], Learning Rate: 0.0001\n",
            "Epoch [2/50], Train Accuracy: 61.986 %, Loss: 1.5224\n",
            "Epoch [2/50], Learning Rate: 0.00208\n",
            "Epoch [3/50], Train Accuracy: 72.812 %, Loss: 0.7060\n",
            "Epoch [3/50], Learning Rate: 0.00406\n",
            "Epoch [4/50], Train Accuracy: 76.15 %, Loss: 0.7351\n",
            "Epoch [4/50], Learning Rate: 0.00604\n",
            "Epoch [5/50], Train Accuracy: 77.25 %, Loss: 0.5531\n",
            "Epoch [5/50], Learning Rate: 0.00802\n",
            "Epoch [6/50], Train Accuracy: 78.488 %, Loss: 0.6231\n",
            "Epoch [6/50], Learning Rate: 0.01\n",
            "Epoch [7/50], Train Accuracy: 78.622 %, Loss: 0.6234\n",
            "Epoch [7/50], Learning Rate: 0.009990232305719944\n",
            "Epoch [8/50], Train Accuracy: 79.122 %, Loss: 0.5968\n",
            "Epoch [8/50], Learning Rate: 0.009960967771506667\n",
            "Epoch [9/50], Train Accuracy: 79.782 %, Loss: 0.5795\n",
            "Epoch [9/50], Learning Rate: 0.00991232189110701\n",
            "Epoch [10/50], Train Accuracy: 80.278 %, Loss: 0.4664\n",
            "Epoch [10/50], Learning Rate: 0.009844486647586723\n",
            "Epoch [11/50], Train Accuracy: 80.73 %, Loss: 0.4841\n",
            "Epoch [11/50], Learning Rate: 0.009757729755661011\n",
            "Epoch [12/50], Train Accuracy: 81.006 %, Loss: 0.5752\n",
            "Epoch [12/50], Learning Rate: 0.009652393605146845\n",
            "Epoch [13/50], Train Accuracy: 80.738 %, Loss: 0.5663\n",
            "Epoch [13/50], Learning Rate: 0.009528893909706798\n",
            "Epoch [14/50], Train Accuracy: 81.078 %, Loss: 0.4977\n",
            "Epoch [14/50], Learning Rate: 0.009387718066217124\n",
            "Epoch [15/50], Train Accuracy: 81.29 %, Loss: 0.5180\n",
            "Epoch [15/50], Learning Rate: 0.009229423231234974\n",
            "Epoch [16/50], Train Accuracy: 81.616 %, Loss: 0.5082\n",
            "Epoch [16/50], Learning Rate: 0.00905463412215599\n",
            "Epoch [17/50], Train Accuracy: 81.412 %, Loss: 0.4859\n",
            "Epoch [17/50], Learning Rate: 0.008864040551740157\n",
            "Epoch [18/50], Train Accuracy: 81.81 %, Loss: 0.5004\n",
            "Epoch [18/50], Learning Rate: 0.008658394705735987\n",
            "Epoch [19/50], Train Accuracy: 81.74 %, Loss: 0.4716\n",
            "Epoch [19/50], Learning Rate: 0.00843850817434701\n",
            "Epoch [20/50], Train Accuracy: 81.618 %, Loss: 0.5360\n",
            "Epoch [20/50], Learning Rate: 0.008205248749256015\n",
            "Epoch [21/50], Train Accuracy: 82.02 %, Loss: 0.6900\n",
            "Epoch [21/50], Learning Rate: 0.007959536998847744\n",
            "Epoch [22/50], Train Accuracy: 82.028 %, Loss: 0.3964\n",
            "Epoch [22/50], Learning Rate: 0.007702342635146034\n",
            "Epoch [23/50], Train Accuracy: 82.222 %, Loss: 0.5855\n",
            "Epoch [23/50], Learning Rate: 0.007434680686803491\n",
            "Epoch [24/50], Train Accuracy: 81.978 %, Loss: 0.5125\n",
            "Epoch [24/50], Learning Rate: 0.0071576074932471105\n",
            "Epoch [25/50], Train Accuracy: 82.312 %, Loss: 0.4753\n",
            "Epoch [25/50], Learning Rate: 0.006872216535789157\n",
            "Epoch [26/50], Train Accuracy: 82.36 %, Loss: 0.4261\n",
            "Epoch [26/50], Learning Rate: 0.006579634122155991\n",
            "Epoch [27/50], Train Accuracy: 82.224 %, Loss: 0.5140\n",
            "Epoch [27/50], Learning Rate: 0.0062810149414660316\n",
            "Epoch [28/50], Train Accuracy: 82.348 %, Loss: 0.5429\n",
            "Epoch [28/50], Learning Rate: 0.005977537507199339\n",
            "Epoch [29/50], Train Accuracy: 82.184 %, Loss: 0.4351\n",
            "Epoch [29/50], Learning Rate: 0.005670399506143308\n",
            "Epoch [30/50], Train Accuracy: 82.516 %, Loss: 0.5168\n",
            "Epoch [30/50], Learning Rate: 0.005360813071670102\n",
            "Epoch [31/50], Train Accuracy: 82.86 %, Loss: 0.4898\n",
            "Epoch [31/50], Learning Rate: 0.005050000000000001\n",
            "Epoch [32/50], Train Accuracy: 82.856 %, Loss: 0.4459\n",
            "Epoch [32/50], Learning Rate: 0.004739186928329899\n",
            "Epoch [33/50], Train Accuracy: 82.862 %, Loss: 0.5356\n",
            "Epoch [33/50], Learning Rate: 0.004429600493856695\n",
            "Epoch [34/50], Train Accuracy: 83.004 %, Loss: 0.5017\n",
            "Epoch [34/50], Learning Rate: 0.0041224624928006635\n",
            "Epoch [35/50], Train Accuracy: 82.98 %, Loss: 0.4925\n",
            "Epoch [35/50], Learning Rate: 0.0038189850585339685\n",
            "Epoch [36/50], Train Accuracy: 82.922 %, Loss: 0.4139\n",
            "Epoch [36/50], Learning Rate: 0.003520365877844012\n",
            "Epoch [37/50], Train Accuracy: 83.052 %, Loss: 0.4049\n",
            "Epoch [37/50], Learning Rate: 0.0032277834642108457\n",
            "Epoch [38/50], Train Accuracy: 83.244 %, Loss: 0.5606\n",
            "Epoch [38/50], Learning Rate: 0.0029423925067528904\n",
            "Epoch [39/50], Train Accuracy: 83.146 %, Loss: 0.4901\n",
            "Epoch [39/50], Learning Rate: 0.002665319313196509\n",
            "Epoch [40/50], Train Accuracy: 83.326 %, Loss: 0.4042\n",
            "Epoch [40/50], Learning Rate: 0.0023976573648539653\n",
            "Epoch [41/50], Train Accuracy: 83.446 %, Loss: 0.5102\n",
            "Epoch [41/50], Learning Rate: 0.0021404630011522584\n",
            "Epoch [42/50], Train Accuracy: 83.314 %, Loss: 0.5281\n",
            "Epoch [42/50], Learning Rate: 0.001894751250743986\n",
            "Epoch [43/50], Train Accuracy: 83.528 %, Loss: 0.4972\n",
            "Epoch [43/50], Learning Rate: 0.001661491825652991\n",
            "Epoch [44/50], Train Accuracy: 83.25 %, Loss: 0.4624\n",
            "Epoch [44/50], Learning Rate: 0.001441605294264014\n",
            "Epoch [45/50], Train Accuracy: 83.442 %, Loss: 0.4537\n",
            "Epoch [45/50], Learning Rate: 0.001235959448259844\n",
            "Epoch [46/50], Train Accuracy: 83.54 %, Loss: 0.4536\n",
            "Epoch [46/50], Learning Rate: 0.0010453658778440107\n",
            "Epoch [47/50], Train Accuracy: 83.486 %, Loss: 0.4112\n",
            "Epoch [47/50], Learning Rate: 0.0008705767687650265\n",
            "Epoch [48/50], Train Accuracy: 83.538 %, Loss: 0.4477\n",
            "Epoch [48/50], Learning Rate: 0.0007122819337828754\n",
            "Epoch [49/50], Train Accuracy: 83.488 %, Loss: 0.4743\n",
            "Epoch [49/50], Learning Rate: 0.0005711060902932043\n",
            "Epoch [50/50], Train Accuracy: 83.508 %, Loss: 0.4687\n",
            "Epoch [50/50], Learning Rate: 0.00044760639485315584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの刈り込み率を計算する関数を作成\n",
        "def calculate_pruned_ratio(model):\n",
        "    total_weights = 0\n",
        "    total_pruned_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        # モジュールがSupermaskConvであるか確認\n",
        "        if isinstance(module, SupermaskConv):\n",
        "            # SupermaskConv層の重みを取得\n",
        "            weight = module.weight.data\n",
        "            # 刈り込みを適用した後の重みを取得\n",
        "            subnet = GetSubnet.apply(module.clamped_scores, 1 - module.prune_rate)\n",
        "            pruned_weight = weight * subnet\n",
        "            # 0である要素数を計算\n",
        "            pruned_weights_count = (pruned_weight == 0).sum().item()\n",
        "            total_pruned_weights += pruned_weights_count\n",
        "            # 重みの全要素数を計算\n",
        "            total_weights_count = pruned_weight.numel()\n",
        "            total_weights += total_weights_count\n",
        "\n",
        "    # 刈り込みが行われた割合を計算\n",
        "    pruned_ratio = total_pruned_weights / total_weights\n",
        "    return print(f\"刈り込み率は{pruned_ratio:.3f}です\")\n",
        "\n",
        "# モデルの刈り込み率を確認\n",
        "calculate_pruned_ratio(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk_gOEAns21L",
        "outputId": "8a0eb9fe-1fdc-4e0c-894f-37b8c14a8938"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "刈り込み率は0.500です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルのスコアを比較する関数を作成\n",
        "def check_scores_change(model, model_init):\n",
        "    # 各モデルの名前付きモジュールを順に調べる\n",
        "    for (name, module), (name_init, module_init) in zip(model.named_modules(), model_init.named_modules()):\n",
        "        # 両モジュールがConv2dのインスタンスであるかを確認\n",
        "        if isinstance(module, torch.nn.Conv2d) and isinstance(module_init, torch.nn.Conv2d):\n",
        "            # 両モジュールが'scores'属性を持っているかを確認\n",
        "            if hasattr(module, 'scores') and hasattr(module_init, 'scores'):\n",
        "                # 両モジュールの'scores'属性が一致しているかを確認\n",
        "                # 一致していない場合、変更があったことを示すメッセージを出力\n",
        "                if not torch.equal(module.scores, module_init.scores):\n",
        "                    print(f'{name}のスコアが変化しています')\n",
        "                    return\n",
        "    # すべてのconv層で'scores'が変更されていない場合、その旨を出力\n",
        "    print('すべてのスコアは変化していません')\n",
        "\n",
        "# 学習前後でモデルのスコアが変化していないかを確認\n",
        "check_scores_change(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw0PWjias21M",
        "outputId": "f2dc87a3-62a4-4c6c-bb72-9b482f0a12dc"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "すべてのスコアは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習前後のモデルの最終層以外の重みを比較する関数を作成\n",
        "def check_weight_change_except_last(model, model_init):\n",
        "    for (name, param), (name_init, param_init) in zip(model.named_parameters(), model_init.named_parameters()):\n",
        "        # 最終層を除く\n",
        "        if name != 'fc.weight' and name != 'fc.bias':\n",
        "            weights_changed = (param.data != param_init.data).any()\n",
        "            if weights_changed:\n",
        "                return print('最終層以外の重みが変化しています')\n",
        "    return print('最終層以外の重みは変化していません')\n",
        "\n",
        "# 学習前後でモデルの最終層以外の重みが変化していないかを確認\n",
        "check_weight_change_except_last(model, model_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8aQW-dBs21M",
        "outputId": "fa175570-333f-4e2a-c610-4f277609ea75"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終層以外の重みは変化していません\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader_cifar10:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    # 正解率精度の確認\n",
        "    print('Test Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q088eN2s21M",
        "outputId": "36175d0c-3a43-4bfd-e642-a5100113b4b5"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.04 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUメモリの解放\n",
        "del model, model_init\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "k9H_mGkns21M"
      },
      "execution_count": 130,
      "outputs": []
    }
  ]
}